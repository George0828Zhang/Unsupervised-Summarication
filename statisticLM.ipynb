{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/hdd/unsupervised-summarization/data-giga/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir+'vocab.json') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir+'train_seq.json') as f:\n",
    "    train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inv = {a:b for b,a in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_record(record, i):\n",
    "    record['count'] += 1\n",
    "    if len(i) > 0 and i[0] >= 0:\n",
    "        if i[0] not in record['next']:\n",
    "            record['next'][i[0]] = {'count': 0, 'next': {}}\n",
    "        record['next'][i[0]] = add_record(record['next'][i[0]], i[1:])\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_record = {'count':0, 'next': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3785004/3785004 [02:57<00:00, 21364.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(train['document']):\n",
    "    s.extend([-1]*1)\n",
    "    for i in range(len(s)-1):\n",
    "        lm_record = add_record(lm_record, s[i:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "class StatisticLM():\n",
    "    def __init__(self, lm_record, vocab, lm_lambda = 0.4):\n",
    "        self.lm_record = lm_record\n",
    "        self.vocab = vocab\n",
    "        self.lm_lambda = lm_lambda\n",
    "    def forward(self, word_ids):\n",
    "        output = torch.zeros((word_ids.shape[0], len(self.vocab))).float()\n",
    "        for b, sen in enumerate(word_ids):\n",
    "            word_list = self.lm_record['next'][sen[-1].item()]\n",
    "            for (k, v) in word_list['next'].items():\n",
    "                output[b, k] = v['count']\n",
    "            output[b] /= word_list['count']\n",
    "            for i in (output[b] == 0).nonzero():\n",
    "                if i.item() in self.lm_record['next']:\n",
    "                    output[b, i] = self.lm_record['next'][i.item()]['count'] / self.lm_record['count'] * self.lm_lambda\n",
    "        output = F.normalize(output, p=1, dim = -1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_LM = StatisticLM(lm_record, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(statistic_LM, 'statistic_LM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
