{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture import ContextMatcher\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm.auto import tqdm\n",
    "data_dir = '/hdd/unsupervised-summarization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.load(open(data_dir+'data-giga/vocab.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ELMo import getELMo\n",
    "# elmo = getELMo(vocab, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(elmo, data_dir+'elmo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'ELMo.LanguageModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.load(data_dir+'data-giga/embeddings.npy')\n",
    "embeddings = torch.from_numpy(embeddings).cuda()\n",
    "elmo = torch.load(data_dir+'elmo_model')\n",
    "elmo_uni = torch.load(data_dir+'elmo_model_uni')\n",
    "lm_elmo = torch.load(data_dir+'LM-check')\n",
    "with open(data_dir+'data-giga/lm_record.json') as f:\n",
    "    lm_record = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statisticalLM import StatisticalLM\n",
    "lm = StatisticalLM(lm_record, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 1.0494e-02, 1.0494e-02,  ..., 4.8521e-07, 5.1848e-07,\n",
       "         4.2421e-07]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.forward(torch.LongTensor([[10, 213]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25133a92a606454aaf8b19e9ebbbdf44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='candidate-mappings', max=157, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d1c46dfcd4436a80dfa46faa0b403f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='candidate-mappings', max=157, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ContextMatcher(\n",
       "  (LM): LanguageModel(\n",
       "    (embed): Embedding(50000, 1024)\n",
       "    (lstm): LSTM(1024, 1024, num_layers=2, batch_first=True, dropout=0.5)\n",
       "    (CE): CrossEntropyLoss()\n",
       "  )\n",
       "  (pretrained_elmo): Elmo(\n",
       "    (_elmo_lstm): _ElmoBiLm(\n",
       "      (_token_embedder): _ElmoCharacterEncoder(\n",
       "        (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "        (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "        (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "        (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "        (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "        (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "        (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "        (_highways): Highway(\n",
       "          (_layers): ModuleList(\n",
       "            (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "            (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (_word_embedding): Embedding()\n",
       "      (_elmo_lstm): ElmoLstm(\n",
       "        (forward_layer_0): LstmCellWithProjection(\n",
       "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "        )\n",
       "        (backward_layer_0): LstmCellWithProjection(\n",
       "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "        )\n",
       "        (forward_layer_1): LstmCellWithProjection(\n",
       "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "        )\n",
       "        (backward_layer_1): LstmCellWithProjection(\n",
       "          (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "          (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "          (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (scalar_mix_0): ScalarMix(\n",
       "      (scalar_parameters): ParameterList(\n",
       "          (0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "          (1): Parameter containing: [torch.FloatTensor of size 1]\n",
       "          (2): Parameter containing: [torch.FloatTensor of size 1]\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = ContextMatcher(embeddings, elmo, lm_elmo)\n",
    "matcher.eval()\n",
    "matcher_uni = ContextMatcher(embeddings, elmo_uni, lm_elmo)\n",
    "matcher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"turnout was heavy for parliamentary elections monday in trinidad and tobage after a month of intensive campaigning throughout the country, one of the most prosperous in the caribbean.\"\n",
    "# raw = \"A dozen current and former staff from different areas of the State Department and at different stages of their careers who spoke to CNN said the Ukraine controversy has exacerbated divisions between political appointees and career diplomats, many of whom say the department is being politicized in ways that undermine US ties to other countries.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [list(nltk.word_tokenize(raw))]\n",
    "# s = [['fuck' if i in ['the', 'The'] else i for i in sen] for sen in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['turnout', 'was', 'heavy', 'for', 'parliamentary', 'elections', 'monday', 'in', 'trinidad', 'and', 'tobage', 'after', 'a', 'month', 'of', 'intensive', 'campaigning', 'throughout', 'the', 'country', ',', 'one', 'of', 'the', 'most', 'prosperous', 'in', 'the', 'caribbean', '.']]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(s)\n",
    "print(len(s[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = [['I', 'have', 'a', 'dog', '!'], ['I', 'have', 'a', 'cat', '.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inv = {a:b for b,a in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(x, y):\n",
    "    return F.cosine_similarity(x, y, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_score(source, now, target):\n",
    "    max_score = -1\n",
    "    max_index = 0\n",
    "\n",
    "    for i in range(now+1, len(source)):\n",
    "        score = similarity(source[i], target)\n",
    "        if max_score < 0 or score > max_score:\n",
    "            max_score = score\n",
    "            max_index = i\n",
    "            \n",
    "    return max_index, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(sourse, cand, matcher, lm):\n",
    "    output = []\n",
    "    now = -1\n",
    "    matcher.voronoi_split(torch.LongTensor(cand))\n",
    "    \n",
    "    while now < len(sourse)-1:\n",
    "\n",
    "        index_list = []\n",
    "        score_list = []\n",
    "        \n",
    "        dist = lm.forward(torch.LongTensor([output]))[0]\n",
    "        t = 0\n",
    "        for w in tqdm(cand):\n",
    "            output_emb = matcher.embed(torch.LongTensor([output+[w]]))[0][-1] ## could be done in batch\n",
    "            index, score = count_score(sourse, now, output_emb)\n",
    "            index_list.append(index)\n",
    "            fm = dist[matcher.get_cell_mates(w)].sum()\n",
    "            t += fm\n",
    "            score_list.append(score + fm)\n",
    "#             print(vocab_inv[w], index, score, fm)\n",
    "\n",
    "        score_list = torch.FloatTensor(score_list)\n",
    "        qcm = F.softmax(score_list, -1)\n",
    "        k = np.argmax(score_list)\n",
    "#         print(k, score_list[k])\n",
    "\n",
    "        output.append(cand[k])\n",
    "        now = index_list[k]\n",
    "#         print(vocab_inv[output[-1]], now)\n",
    "    \n",
    "    output = [vocab_inv[i] for i in output]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_batch(s, matcher, lm):\n",
    "    print(s)\n",
    "    s_index = [[ vocab.get(w.lower(), vocab[\"<unk>\"]) for w in sen] for sen in s]\n",
    "    s_index = torch.LongTensor(s_index)\n",
    "    s_emb = matcher.embed(s_index)\n",
    "    output_list = []\n",
    "    for index, target in enumerate(s_emb):\n",
    "        vocab_list = matcher.candidate_list(s_index[index], 2).numpy()\n",
    "        output = summary(target, vocab_list, matcher, lm)\n",
    "        output_list.append(output)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['turnout', 'was', 'heavy', 'for', 'parliamentary', 'elections', 'monday', 'in', 'trinidad', 'and', 'tobage', 'after', 'a', 'month', 'of', 'intensive', 'campaigning', 'throughout', 'the', 'country', ',', 'one', 'of', 'the', 'most', 'prosperous', 'in', 'the', 'caribbean', '.']]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7217d7b08141e68df2ad3afc15bada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=52), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = summary_batch(s, matcher, lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['turnout', 'was', 'heavy', 'for', 'parliamentary', 'elections', 'monday', 'in', 'trinidad', 'and', 'tobage', 'after', 'a', 'month', 'of', 'intensive', 'campaigning', 'throughout', 'the', 'country', ',', 'one', 'of', 'the', 'most', 'prosperous', 'in', 'the', 'caribbean', '.']]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9d5a640ab44429b9fc9dad820e0e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=52), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2be87b4a8bc4ab6a80421feac2da3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=52), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046cde6b5a7643afaa5f8f37401f58c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=52), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6363b43bda3a4445aea722f8116cd07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=52), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = summary_batch(s, matcher_uni, lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.'] ['turnout was campaigned .']\n",
      "turnout was heavy for parliamentary elections monday in trinidad and tobage after a month of intensive campaigning throughout the country , one of the most prosperous in the caribbean .\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print([' '.join(s) for s in result1], [' '.join(s) for s in result2])\n",
    "print(' '.join(s[0]))\n",
    "print(len(s[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_index = [[ vocab.get(w.lower(), vocab[\"<unk>\"]) for w in sen] for sen in s]\n",
    "s_index = torch.LongTensor(s_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.voronoi_split(matcher.candidate_list(s_index[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(s_index[0])):\n",
    "    print(matcher_uni.embed(s_index[0][:i+1].unsqueeze(0))[:, -1, :].sum(), vocab_inv[s_index[0][i].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.candidate_list(s_index[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.candidate_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.embeddings[vocab['turnout']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.embed(s_index[0][:54].unsqueeze(0))[:, -1, :].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_index[0][:54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = [] \n",
    "for i in range(10):\n",
    "    e = matcher.embed(torch.LongTensor([[vocab['<S>'], vocab['chicken'], vocab['.']]]))[:,-1, :]\n",
    "    embs.append(e.squeeze())\n",
    "embs = torch.stack(embs, dim=0)\n",
    "print(embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = F.normalize(embs, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.matmul(embs, embs.transpose(-2, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
