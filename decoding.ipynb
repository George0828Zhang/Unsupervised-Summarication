{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture import ContextMatcher\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import nltk\n",
    "data_dir = '/hdd/unsupervised-summarization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.load(open(data_dir+'data-giga/vocab.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = ContextMatcher(vocab, data_dir+'trainedELMo', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"A dozen current and former staff from different areas of the State Department and at different stages of their careers who spoke to CNN said the Ukraine controversy has exacerbated divisions between political appointees and career diplomats, many of whom say the department is being politicized in ways that undermine US ties to other countries.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [list(nltk.word_tokenize(raw))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A', 'dozen', 'current', 'and', 'former', 'staff', 'from', 'different', 'areas', 'of', 'the', 'State', 'Department', 'and', 'at', 'different', 'stages', 'of', 'their', 'careers', 'who', 'spoke', 'to', 'CNN', 'said', 'the', 'Ukraine', 'controversy', 'has', 'exacerbated', 'divisions', 'between', 'political', 'appointees', 'and', 'career', 'diplomats', ',', 'many', 'of', 'whom', 'say', 'the', 'department', 'is', 'being', 'politicized', 'in', 'ways', 'that', 'undermine', 'US', 'ties', 'to', 'other', 'countries', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = [['I', 'have', 'a', 'dog', '!'], ['I', 'have', 'a', 'cat', '.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inv = {a:b for b,a in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(x, y):\n",
    "    return F.cosine_similarity(x, y, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_score(sourse, now, target):\n",
    "    max_score = -1\n",
    "    max_index = 0\n",
    "\n",
    "    for i in range(now+1, len(sourse)):\n",
    "        score = similarity(sourse[now], target)\n",
    "\n",
    "        if max_score < 0 or score > max_score:\n",
    "            max_score = score\n",
    "            max_index = i\n",
    "            \n",
    "    return max_index, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(sourse, vocab, matcher):\n",
    "    output = []\n",
    "    now = -1\n",
    "    while now < len(sourse)-1:\n",
    "\n",
    "        index_list = []\n",
    "        score_list = []\n",
    "        for w in vocab:\n",
    "            print(w, end='\\r')\n",
    "            output_emb = matcher.embed(torch.LongTensor([output+[w]]))[0][-1] ## could be done in batch\n",
    "            index, score = count_score(sourse, now, output_emb)\n",
    "            index_list.append(index)\n",
    "            score_list.append(index)\n",
    "        score_list = torch.FloatTensor(score_list)\n",
    "        qcm = F.softmax(score_list, -1)\n",
    "        k = np.argmax(score_list)\n",
    "\n",
    "        output.append(vocab[k])\n",
    "        now = index_list[k]\n",
    "        print(vocab_inv[vocab[k]])\n",
    "    \n",
    "    output = [vocab_inv[i] for i in output]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_batch(s, matcher):\n",
    "    s_index = [[ vocab[w.lower()] for w in sen] for sen in s]\n",
    "    s_index = torch.LongTensor(s_index)\n",
    "    s_emb = matcher.embed(s_index)\n",
    "    output_list = []\n",
    "    for target in s_emb:\n",
    "        print(target.shape)\n",
    "#         vocab_list = list(range(len(vocab)))\n",
    "        vocab_list = list(range(10000, 20000))\n",
    "        output = summary(target, vocab_list, matcher)\n",
    "        output_list.append(output)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 1024])\n",
      "everywhere\n",
      "wrangling\n"
     ]
    }
   ],
   "source": [
    "result = summary_batch(s, matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
